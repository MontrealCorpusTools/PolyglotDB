{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: First steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the tutorial corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tutorial corpus used here is a version of the [LibriSpeech](http://www.openslr.org/12/) test-clean subset, forced aligned with the\n",
    "[Montreal Forced Aligner](https://montreal-forced-aligner.readthedocs.io/en/latest/) ([tutorial corpus download link](https://mcgill-my.sharepoint.com/:u:/g/personal/michael_haaf_mcgill_ca/EfocNOr3o7xJuCrG_-OrR3MBh_-vmQaHtkV2J7vJq61c1w?e=UEhQg7)).  Extract the files to somewhere on your local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the tutorial corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by importing the necessary classes and functions from polyglotdb as well as defining variables.  Change the path to reflect where the tutorial corpus was extracted to on your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polyglotdb import CorpusContext\n",
    "import polyglotdb.io as pgio\n",
    "\n",
    "corpus_root = '/mnt/e/Data/pg_tutorial'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The import statements get the necessary classes and functions for importing, namely the CorpusContext class and\n",
    "the polyglot IO module.  CorpusContext objects are how all interactions with the database are handled.  The CorpusContext is\n",
    "created as a context manager in Python (the ``with ... as ...`` pattern), so that clean up and closing of connections are\n",
    "automatically handled both on successful completion of the code as well as if errors are encountered.\n",
    "\n",
    "The IO module handles all import and export functionality in polyglotdb.  The principle functions that a user will encounter\n",
    "are the ``inspect_X`` functions that generate parsers for corpus formats.  In the above code, the MFA parser is used because\n",
    "the tutorial corpus was aligned using the MFA.  See [Importing corpora](https://polyglotdb.readthedocs.io/en/latest/import.html) for more information on the inspect functions and parser\n",
    "objects they generate for various formats.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the proper path to the tutorial corpus is set, it can be imported via the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading /mnt/e/Data/pg_tutorial with <polyglotdb.io.parsers.mfa.MfaParser object at 0x7f8d740a0208>\n",
      "Finding  files...\n",
      "0 0\n",
      "Parsing types...\n",
      "0 87\n",
      "Parsing types from file 1 of 87...\n",
      "0\n",
      "Parsing types from file 2 of 87...\n",
      "1\n",
      "Parsing types from file 3 of 87...\n",
      "2\n",
      "Parsing types from file 4 of 87...\n",
      "3\n",
      "Parsing types from file 5 of 87...\n",
      "4\n",
      "Parsing types from file 6 of 87...\n",
      "5\n",
      "Parsing types from file 7 of 87...\n",
      "6\n",
      "Parsing types from file 8 of 87...\n",
      "7\n",
      "Parsing types from file 9 of 87...\n",
      "8\n",
      "Parsing types from file 10 of 87...\n",
      "9\n",
      "Parsing types from file 11 of 87...\n",
      "10\n",
      "Parsing types from file 12 of 87...\n",
      "11\n",
      "Parsing types from file 13 of 87...\n",
      "12\n",
      "Parsing types from file 14 of 87...\n",
      "13\n",
      "Parsing types from file 15 of 87...\n",
      "14\n",
      "Parsing types from file 16 of 87...\n",
      "15\n",
      "Parsing types from file 17 of 87...\n",
      "16\n",
      "Parsing types from file 18 of 87...\n",
      "17\n",
      "Parsing types from file 19 of 87...\n",
      "18\n",
      "Parsing types from file 20 of 87...\n",
      "19\n",
      "Parsing types from file 21 of 87...\n",
      "20\n",
      "Parsing types from file 22 of 87...\n",
      "21\n",
      "Parsing types from file 23 of 87...\n",
      "22\n",
      "Parsing types from file 24 of 87...\n",
      "23\n",
      "Parsing types from file 25 of 87...\n",
      "24\n",
      "Parsing types from file 26 of 87...\n",
      "25\n",
      "Parsing types from file 27 of 87...\n",
      "26\n",
      "Parsing types from file 28 of 87...\n",
      "27\n",
      "Parsing types from file 29 of 87...\n",
      "28\n",
      "Parsing types from file 30 of 87...\n",
      "29\n",
      "Parsing types from file 31 of 87...\n",
      "30\n",
      "Parsing types from file 32 of 87...\n",
      "31\n",
      "Parsing types from file 33 of 87...\n",
      "32\n",
      "Parsing types from file 34 of 87...\n",
      "33\n",
      "Parsing types from file 35 of 87...\n",
      "34\n",
      "Parsing types from file 36 of 87...\n",
      "35\n",
      "Parsing types from file 37 of 87...\n",
      "36\n",
      "Parsing types from file 38 of 87...\n",
      "37\n",
      "Parsing types from file 39 of 87...\n",
      "38\n",
      "Parsing types from file 40 of 87...\n",
      "39\n",
      "Parsing types from file 41 of 87...\n",
      "40\n",
      "Parsing types from file 42 of 87...\n",
      "41\n",
      "Parsing types from file 43 of 87...\n",
      "42\n",
      "Parsing types from file 44 of 87...\n",
      "43\n",
      "Parsing types from file 45 of 87...\n",
      "44\n",
      "Parsing types from file 46 of 87...\n",
      "45\n",
      "Parsing types from file 47 of 87...\n",
      "46\n",
      "Parsing types from file 48 of 87...\n",
      "47\n",
      "Parsing types from file 49 of 87...\n",
      "48\n",
      "Parsing types from file 50 of 87...\n",
      "49\n",
      "Parsing types from file 51 of 87...\n",
      "50\n",
      "Parsing types from file 52 of 87...\n",
      "51\n",
      "Parsing types from file 53 of 87...\n",
      "52\n",
      "Parsing types from file 54 of 87...\n",
      "53\n",
      "Parsing types from file 55 of 87...\n",
      "54\n",
      "Parsing types from file 56 of 87...\n",
      "55\n",
      "Parsing types from file 57 of 87...\n",
      "56\n",
      "Parsing types from file 58 of 87...\n",
      "57\n",
      "Parsing types from file 59 of 87...\n",
      "58\n",
      "Parsing types from file 60 of 87...\n",
      "59\n",
      "Parsing types from file 61 of 87...\n",
      "60\n",
      "Parsing types from file 62 of 87...\n",
      "61\n",
      "Parsing types from file 63 of 87...\n",
      "62\n",
      "Parsing types from file 64 of 87...\n",
      "63\n",
      "Parsing types from file 65 of 87...\n",
      "64\n",
      "Parsing types from file 66 of 87...\n",
      "65\n",
      "Parsing types from file 67 of 87...\n",
      "66\n",
      "Parsing types from file 68 of 87...\n",
      "67\n",
      "Parsing types from file 69 of 87...\n",
      "68\n",
      "Parsing types from file 70 of 87...\n",
      "69\n",
      "Parsing types from file 71 of 87...\n",
      "70\n",
      "Parsing types from file 72 of 87...\n",
      "71\n",
      "Parsing types from file 73 of 87...\n",
      "72\n",
      "Parsing types from file 74 of 87...\n",
      "73\n",
      "Parsing types from file 75 of 87...\n",
      "74\n",
      "Parsing types from file 76 of 87...\n",
      "75\n",
      "Parsing types from file 77 of 87...\n",
      "76\n",
      "Parsing types from file 78 of 87...\n",
      "77\n",
      "Parsing types from file 79 of 87...\n",
      "78\n",
      "Parsing types from file 80 of 87...\n",
      "79\n",
      "Parsing types from file 81 of 87...\n",
      "80\n",
      "Parsing types from file 82 of 87...\n",
      "81\n",
      "Parsing types from file 83 of 87...\n",
      "82\n",
      "Parsing types from file 84 of 87...\n",
      "83\n",
      "Parsing types from file 85 of 87...\n",
      "84\n",
      "Parsing types from file 86 of 87...\n",
      "85\n",
      "Parsing types from file 87 of 87...\n",
      "86\n",
      "Importing types...\n",
      "Parsing files...\n",
      "0 87\n",
      "Parsing file 1 of 87 (134686)...\n",
      "0\n",
      "Parsing file 2 of 87 (134691)...\n",
      "1\n",
      "Parsing file 3 of 87 (133604)...\n",
      "2\n",
      "Parsing file 4 of 87 (121726)...\n",
      "3\n",
      "Parsing file 5 of 87 (123852)...\n",
      "4\n",
      "Parsing file 6 of 87 (123859)...\n",
      "5\n",
      "Parsing file 7 of 87 (127105)...\n",
      "6\n",
      "Parsing file 8 of 87 (135766)...\n",
      "7\n",
      "Parsing file 9 of 87 (135767)...\n",
      "8\n",
      "Parsing file 10 of 87 (1180)...\n",
      "9\n",
      "Parsing file 11 of 87 (1181)...\n",
      "10\n",
      "Parsing file 12 of 87 (134647)...\n",
      "11\n",
      "Parsing file 13 of 87 (122612)...\n",
      "12\n",
      "Parsing file 14 of 87 (122617)...\n",
      "13\n",
      "Parsing file 15 of 87 (141083)...\n",
      "14\n",
      "Parsing file 16 of 87 (141084)...\n",
      "15\n",
      "Parsing file 17 of 87 (1826)...\n",
      "16\n",
      "Parsing file 18 of 87 (1836)...\n",
      "17\n",
      "Parsing file 19 of 87 (1837)...\n",
      "18\n",
      "Parsing file 20 of 87 (142345)...\n",
      "19\n",
      "Parsing file 21 of 87 (131720)...\n",
      "20\n",
      "Parsing file 22 of 87 (126133)...\n",
      "21\n",
      "Parsing file 23 of 87 (134493)...\n",
      "22\n",
      "Parsing file 24 of 87 (134500)...\n",
      "23\n",
      "Parsing file 25 of 87 (123286)...\n",
      "24\n",
      "Parsing file 26 of 87 (123288)...\n",
      "25\n",
      "Parsing file 27 of 87 (123440)...\n",
      "26\n",
      "Parsing file 28 of 87 (3979)...\n",
      "27\n",
      "Parsing file 29 of 87 (3980)...\n",
      "28\n",
      "Parsing file 30 of 87 (960)...\n",
      "29\n",
      "Parsing file 31 of 87 (961)...\n",
      "30\n",
      "Parsing file 32 of 87 (5694)...\n",
      "31\n",
      "Parsing file 33 of 87 (5695)...\n",
      "32\n",
      "Parsing file 34 of 87 (5696)...\n",
      "33\n",
      "Parsing file 35 of 87 (170457)...\n",
      "34\n",
      "Parsing file 36 of 87 (6852)...\n",
      "35\n",
      "Parsing file 37 of 87 (13751)...\n",
      "36\n",
      "Parsing file 38 of 87 (13754)...\n",
      "37\n",
      "Parsing file 39 of 87 (2271)...\n",
      "38\n",
      "Parsing file 40 of 87 (2273)...\n",
      "39\n",
      "Parsing file 41 of 87 (2275)...\n",
      "40\n",
      "Parsing file 42 of 87 (16021)...\n",
      "41\n",
      "Parsing file 43 of 87 (29093)...\n",
      "42\n",
      "Parsing file 44 of 87 (29095)...\n",
      "43\n",
      "Parsing file 45 of 87 (23283)...\n",
      "44\n",
      "Parsing file 46 of 87 (41797)...\n",
      "45\n",
      "Parsing file 47 of 87 (41806)...\n",
      "46\n",
      "Parsing file 48 of 87 (28233)...\n",
      "47\n",
      "Parsing file 49 of 87 (28240)...\n",
      "48\n",
      "Parsing file 50 of 87 (28241)...\n",
      "49\n",
      "Parsing file 51 of 87 (33396)...\n",
      "50\n",
      "Parsing file 52 of 87 (36377)...\n",
      "51\n",
      "Parsing file 53 of 87 (36586)...\n",
      "52\n",
      "Parsing file 54 of 87 (36600)...\n",
      "53\n",
      "Parsing file 55 of 87 (40744)...\n",
      "54\n",
      "Parsing file 56 of 87 (32865)...\n",
      "55\n",
      "Parsing file 57 of 87 (32866)...\n",
      "56\n",
      "Parsing file 58 of 87 (32879)...\n",
      "57\n",
      "Parsing file 59 of 87 (70968)...\n",
      "58\n",
      "Parsing file 60 of 87 (70970)...\n",
      "59\n",
      "Parsing file 61 of 87 (122797)...\n",
      "60\n",
      "Parsing file 62 of 87 (68769)...\n",
      "61\n",
      "Parsing file 63 of 87 (68771)...\n",
      "62\n",
      "Parsing file 64 of 87 (75918)...\n",
      "63\n",
      "Parsing file 65 of 87 (76324)...\n",
      "64\n",
      "Parsing file 66 of 87 (81414)...\n",
      "65\n",
      "Parsing file 67 of 87 (79730)...\n",
      "66\n",
      "Parsing file 68 of 87 (79740)...\n",
      "67\n",
      "Parsing file 69 of 87 (79759)...\n",
      "68\n",
      "Parsing file 70 of 87 (85628)...\n",
      "69\n",
      "Parsing file 71 of 87 (75946)...\n",
      "70\n",
      "Parsing file 72 of 87 (75947)...\n",
      "71\n",
      "Parsing file 73 of 87 (88083)...\n",
      "72\n",
      "Parsing file 74 of 87 (92135)...\n",
      "73\n",
      "Parsing file 75 of 87 (102255)...\n",
      "74\n",
      "Parsing file 76 of 87 (274381)...\n",
      "75\n",
      "Parsing file 77 of 87 (274384)...\n",
      "76\n",
      "Parsing file 78 of 87 (279154)...\n",
      "77\n",
      "Parsing file 79 of 87 (210777)...\n",
      "78\n",
      "Parsing file 80 of 87 (287645)...\n",
      "79\n",
      "Parsing file 81 of 87 (294825)...\n",
      "80\n",
      "Parsing file 82 of 87 (294828)...\n",
      "81\n",
      "Parsing file 83 of 87 (284447)...\n",
      "82\n",
      "Parsing file 84 of 87 (284449)...\n",
      "83\n",
      "Parsing file 85 of 87 (292519)...\n",
      "84\n",
      "Parsing file 86 of 87 (157963)...\n",
      "85\n",
      "Parsing file 87 of 87 (31957)...\n",
      "86\n",
      "Importing data...\n",
      "0 80\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "Importing data for speaker 0 of 40 (1089)...\n",
      "Importing data for speaker 1 of 40 (1188)...\n",
      "Importing data for speaker 2 of 40 (121)...\n",
      "Importing data for speaker 3 of 40 (1221)...\n",
      "Importing data for speaker 4 of 40 (1284)...\n",
      "Importing data for speaker 5 of 40 (1320)...\n",
      "Importing data for speaker 6 of 40 (1580)...\n",
      "Importing data for speaker 7 of 40 (1995)...\n",
      "Importing data for speaker 8 of 40 (2094)...\n",
      "Importing data for speaker 9 of 40 (2300)...\n",
      "Importing data for speaker 10 of 40 (237)...\n",
      "Importing data for speaker 11 of 40 (260)...\n",
      "Importing data for speaker 12 of 40 (2830)...\n",
      "Importing data for speaker 13 of 40 (2961)...\n",
      "Importing data for speaker 14 of 40 (3570)...\n",
      "Importing data for speaker 15 of 40 (3575)...\n",
      "Importing data for speaker 16 of 40 (3729)...\n",
      "Importing data for speaker 17 of 40 (4077)...\n",
      "Importing data for speaker 18 of 40 (4446)...\n",
      "Importing data for speaker 19 of 40 (4507)...\n",
      "Importing data for speaker 20 of 40 (4970)...\n",
      "Importing data for speaker 21 of 40 (4992)...\n",
      "Importing data for speaker 22 of 40 (5105)...\n",
      "Importing data for speaker 23 of 40 (5142)...\n",
      "Importing data for speaker 24 of 40 (5639)...\n",
      "Importing data for speaker 25 of 40 (5683)...\n",
      "Importing data for speaker 26 of 40 (61)...\n",
      "Importing data for speaker 27 of 40 (672)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing data for speaker 28 of 40 (6829)...\n",
      "Importing data for speaker 29 of 40 (6930)...\n",
      "Importing data for speaker 30 of 40 (7021)...\n",
      "Importing data for speaker 31 of 40 (7127)...\n",
      "Importing data for speaker 32 of 40 (7176)...\n",
      "Importing data for speaker 33 of 40 (7729)...\n",
      "Importing data for speaker 34 of 40 (8224)...\n",
      "Importing data for speaker 35 of 40 (8230)...\n",
      "Importing data for speaker 36 of 40 (8455)...\n",
      "Importing data for speaker 37 of 40 (8463)...\n",
      "Importing data for speaker 38 of 40 (8555)...\n",
      "Importing data for speaker 39 of 40 (908)...\n"
     ]
    }
   ],
   "source": [
    "parser = pgio.inspect_mfa(corpus_root)\n",
    "parser.call_back = print # To show progress output\n",
    "\n",
    "with CorpusContext('pg_tutorial') as c:\n",
    "    c.load(parser, corpus_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Important\n",
    "\n",
    "If during the running of the import code, a ``neo4j.exceptions.ServiceUnavailable`` error is raised, then double check\n",
    "that the pgdb database is running.  Once polyglotdb is installed, simply call ``pgdb start``, assuming ``pgdb install``\n",
    "has already been called.  See [the relevant documentation](https://polyglotdb.readthedocs.io/en/latest/getting_started.html#set-up-local-database) for more information.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resetting the corpus \n",
    "\n",
    "If at any point there's some error or interruption in import or other stages of the tutorial, the corpus can be reset to a\n",
    "fresh state via the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with CorpusContext('pg_tutorial') as c:\n",
    "    c.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Warning\n",
    "\n",
    "Be careful when running this code as it will delete any and all information in the corpus.  For smaller corpora such\n",
    "as the one presented here, the time to set up is not huge, but for larger corpora this can result in several hours worth\n",
    "of time to reimport and re-enrich the corpus.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing some simple queries \n",
    "\n",
    "To ensure that data import completed successfully, we can print the list of speakers, discourses, and phone types in the corpus, via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speakers: ['2300', '1580', '237', '260', '1995', '2830', '2961', '3570', '2094', '1089', '1188', '121', '1221', '1284', '1320', '3575', '3729', '4077', '4446', '4507', '4970', '4992', '5105', '5142', '5639', '5683', '61', '672', '6829', '6930', '7021', '7127', '7176', '7729', '8224', '8230', '8455', '8463', '8555', '908']\n",
      "Discourses: ['5696', '122617', '142345', '131720', '141083', '126133', '134493', '134500', '141084', '123286', '123288', '123440', '1826', '3979', '3980', '1836', '960', '1837', '961', '5694', '5695', '134686', '134691', '133604', '121726', '123852', '123859', '127105', '135766', '135767', '1180', '1181', '134647', '122612', '170457', '6852', '13751', '13754', '2271', '2273', '2275', '16021', '29093', '29095', '23283', '41797', '41806', '28233', '28240', '28241', '33396', '36377', '36586', '36600', '40744', '32865', '32866', '32879', '70968', '70970', '122797', '68769', '68771', '75918', '76324', '81414', '79730', '79740', '79759', '85628', '75946', '75947', '88083', '92135', '102255', '274381', '274384', '279154', '210777', '287645', '294825', '294828', '284447', '284449', '292519', '157963', '31957']\n",
      "phone: <SIL>\n",
      "phone: AA0\n",
      "phone: AA1\n",
      "phone: AA2\n",
      "phone: AE0\n",
      "phone: AE1\n",
      "phone: AE2\n",
      "phone: AH0\n",
      "phone: AH1\n",
      "phone: AH2\n",
      "phone: AO0\n",
      "phone: AO1\n",
      "phone: AO2\n",
      "phone: AW0\n",
      "phone: AW1\n",
      "phone: AW2\n",
      "phone: AY0\n",
      "phone: AY1\n",
      "phone: AY2\n",
      "phone: B\n",
      "phone: CH\n",
      "phone: D\n",
      "phone: DH\n",
      "phone: EH0\n",
      "phone: EH1\n",
      "phone: EH2\n",
      "phone: ER0\n",
      "phone: ER1\n",
      "phone: ER2\n",
      "phone: EY0\n",
      "phone: EY1\n",
      "phone: EY2\n",
      "phone: F\n",
      "phone: G\n",
      "phone: HH\n",
      "phone: IH0\n",
      "phone: IH1\n",
      "phone: IH2\n",
      "phone: IY0\n",
      "phone: IY1\n",
      "phone: IY2\n",
      "phone: JH\n",
      "phone: K\n",
      "phone: L\n",
      "phone: M\n",
      "phone: N\n",
      "phone: NG\n",
      "phone: OW0\n",
      "phone: OW1\n",
      "phone: OW2\n",
      "phone: OY1\n",
      "phone: OY2\n",
      "phone: P\n",
      "phone: R\n",
      "phone: S\n",
      "phone: SH\n",
      "phone: T\n",
      "phone: TH\n",
      "phone: UH0\n",
      "phone: UH1\n",
      "phone: UH2\n",
      "phone: UW0\n",
      "phone: UW1\n",
      "phone: UW2\n",
      "phone: V\n",
      "phone: W\n",
      "phone: Y\n",
      "phone: Z\n",
      "phone: ZH\n",
      "phone: sil\n",
      "phone: spn\n"
     ]
    }
   ],
   "source": [
    "with CorpusContext('pg_tutorial') as c:\n",
    "    print('Speakers:', c.speakers)\n",
    "    print('Discourses:', c.discourses)\n",
    "    q = c.query_lexicon(c.lexicon_phone)\n",
    "    \n",
    "    q = q.order_by(c.lexicon_phone.label)\n",
    "    q = q.columns(c.lexicon_phone.label.column_name('phone'))\n",
    "    results = q.all()\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more interesting summary query is perhaps looking at the count and average duration of different phone types across the corpus, via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The phone <SIL> had 166 occurrences and an average duration of 0.017469503012048297.\n",
      "The phone AA0 had 1 occurrences and an average duration of 0.08999999999999986.\n",
      "The phone AA1 had 136 occurrences and an average duration of 0.1100735294117647.\n",
      "The phone AA2 had 4 occurrences and an average duration of 0.06749999999999995.\n",
      "The phone AE0 had 1 occurrences and an average duration of 0.10000000000000009.\n",
      "The phone AE1 had 200 occurrences and an average duration of 0.10715000000000004.\n",
      "The phone AE2 had 9 occurrences and an average duration of 0.10333333333333337.\n",
      "The phone AH0 had 660 occurrences and an average duration of 0.05842424242424243.\n",
      "The phone AH1 had 207 occurrences and an average duration of 0.07285024154589363.\n",
      "The phone AH2 had 3 occurrences and an average duration of 0.04666666666666669.\n",
      "The phone AO0 had 3 occurrences and an average duration of 0.07333333333333325.\n",
      "The phone AO1 had 124 occurrences and an average duration of 0.11306451612903229.\n",
      "The phone AO2 had 3 occurrences and an average duration of 0.08333333333333348.\n",
      "The phone AW1 had 51 occurrences and an average duration of 0.15039215686274507.\n",
      "The phone AW2 had 1 occurrences and an average duration of 0.09999999999999998.\n",
      "The phone AY0 had 1 occurrences and an average duration of 0.08000000000000007.\n",
      "The phone AY1 had 186 occurrences and an average duration of 0.16607526881720436.\n",
      "The phone AY2 had 12 occurrences and an average duration of 0.10999999999999993.\n",
      "The phone B had 169 occurrences and an average duration of 0.06952662721893489.\n",
      "The phone CH had 46 occurrences and an average duration of 0.11260869565217384.\n",
      "The phone D had 408 occurrences and an average duration of 0.06436274509803926.\n",
      "The phone DH had 292 occurrences and an average duration of 0.055479452054794556.\n",
      "The phone EH0 had 5 occurrences and an average duration of 0.06399999999999997.\n",
      "The phone EH1 had 266 occurrences and an average duration of 0.07954887218045116.\n",
      "The phone ER0 had 161 occurrences and an average duration of 0.08621118012422359.\n",
      "The phone ER1 had 42 occurrences and an average duration of 0.12023809523809523.\n",
      "The phone EY1 had 140 occurrences and an average duration of 0.14292857142857154.\n",
      "The phone EY2 had 2 occurrences and an average duration of 0.13999999999999996.\n",
      "The phone F had 172 occurrences and an average duration of 0.1013953488372093.\n",
      "The phone G had 73 occurrences and an average duration of 0.083972602739726.\n",
      "The phone HH had 226 occurrences and an average duration of 0.0774778761061947.\n",
      "The phone IH0 had 311 occurrences and an average duration of 0.05758842443729905.\n",
      "The phone IH1 had 220 occurrences and an average duration of 0.08281818181818185.\n",
      "The phone IH2 had 8 occurrences and an average duration of 0.04750000000000003.\n",
      "The phone IY0 had 146 occurrences and an average duration of 0.1004109589041096.\n",
      "The phone IY1 had 172 occurrences and an average duration of 0.11540697674418608.\n",
      "The phone IY2 had 2 occurrences and an average duration of 0.09000000000000002.\n",
      "The phone JH had 32 occurrences and an average duration of 0.0987499999999999.\n",
      "The phone K had 225 occurrences and an average duration of 0.09422222222222218.\n",
      "The phone L had 353 occurrences and an average duration of 0.0886968838526912.\n",
      "The phone M had 252 occurrences and an average duration of 0.08694444444444441.\n",
      "The phone N had 604 occurrences and an average duration of 0.07475165562913916.\n",
      "The phone NG had 94 occurrences and an average duration of 0.0987234042553192.\n",
      "The phone OW0 had 17 occurrences and an average duration of 0.1382352941176471.\n",
      "The phone OW1 had 110 occurrences and an average duration of 0.14209090909090916.\n",
      "The phone OW2 had 2 occurrences and an average duration of 0.05499999999999988.\n",
      "The phone OY1 had 10 occurrences and an average duration of 0.21199999999999997.\n",
      "The phone P had 165 occurrences and an average duration of 0.09848484848484848.\n",
      "The phone R had 412 occurrences and an average duration of 0.07725728155339802.\n",
      "The phone S had 434 occurrences and an average duration of 0.10951612903225806.\n",
      "The phone SH had 66 occurrences and an average duration of 0.10787878787878787.\n",
      "The phone T had 672 occurrences and an average duration of 0.08217261904761902.\n",
      "The phone TH had 77 occurrences and an average duration of 0.10454545454545451.\n",
      "The phone UH0 had 2 occurrences and an average duration of 0.030000000000000138.\n",
      "The phone UH1 had 43 occurrences and an average duration of 0.07395348837209305.\n",
      "The phone UH2 had 2 occurrences and an average duration of 0.054999999999999716.\n",
      "The phone UW0 had 5 occurrences and an average duration of 0.09600000000000004.\n",
      "The phone UW1 had 103 occurrences and an average duration of 0.09601941747572817.\n",
      "The phone UW2 had 2 occurrences and an average duration of 0.10499999999999998.\n",
      "The phone V had 152 occurrences and an average duration of 0.07631578947368427.\n",
      "The phone W had 239 occurrences and an average duration of 0.07301255230125528.\n",
      "The phone Y had 71 occurrences and an average duration of 0.08915492957746479.\n",
      "The phone Z had 261 occurrences and an average duration of 0.09003831417624521.\n",
      "The phone ZH had 2 occurrences and an average duration of 0.11999999999999966.\n",
      "The phone sil had 607 occurrences and an average duration of 0.28601317957166394.\n",
      "The phone spn had 35 occurrences and an average duration of 0.5399999999999999.\n"
     ]
    }
   ],
   "source": [
    "from polyglotdb.query.base.func import Count, Average\n",
    "\n",
    "with CorpusContext('pg_tutorial') as c:\n",
    "    # Optional: Use order_by to enforce ordering on the output for easier comparison with the sample output.\n",
    "    q = c.query_graph(c.phone).order_by(c.phone.label).group_by(c.phone.label.column_name('phone'))\n",
    "    results = q.aggregate(Count().column_name('count'), Average(c.phone.duration).column_name('average_duration'))\n",
    "    for r in results:\n",
    "        print('The phone {} had {} occurrences and an average duration of {}.'.format(r['phone'], r['count'], r['average_duration']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
